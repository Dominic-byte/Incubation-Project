{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ru622XNysalT"
   },
   "source": [
    "https://www.pyimagesearch.com/2020/06/01/opencv-social-distancing-detector/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model link\n",
    "https://drive.google.com/file/d/1HJ5tUTd9r92I-LMRf6tZPD2M1SHqmzk-/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1044,
     "status": "ok",
     "timestamp": 1599813577752,
     "user": {
      "displayName": "Parking Incubate",
      "photoUrl": "",
      "userId": "15470270347258067289"
     },
     "user_tz": -120
    },
    "id": "0_rqhfREqnZ3",
    "outputId": "26b98d1e-ab87-4a8a-a6ea-9d80621e00fc",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Parking Classifier/0 Manual Parking\n"
     ]
    }
   ],
   "source": [
    "%cd \"/content/drive/My Drive/Parking Classifier/0 Manual Parking\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1069,
     "status": "ok",
     "timestamp": 1599813585771,
     "user": {
      "displayName": "Parking Incubate",
      "photoUrl": "",
      "userId": "15470270347258067289"
     },
     "user_tz": -120
    },
    "id": "pnHfvh5kqNpe"
   },
   "outputs": [],
   "source": [
    "# @title Constants\n",
    "# base path to YOLO directory\n",
    "MODEL_PATH = \"yolo-coco\"\n",
    "\n",
    "# initialize minimum probability to filter weak detections along with\n",
    "# the threshold when applying non-maxima suppression\n",
    "MIN_CONF = 0.3\n",
    "NMS_THRESH = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1376,
     "status": "ok",
     "timestamp": 1599813588764,
     "user": {
      "displayName": "Parking Incubate",
      "photoUrl": "",
      "userId": "15470270347258067289"
     },
     "user_tz": -120
    },
    "id": "3jKwm3c8sBs1"
   },
   "outputs": [],
   "source": [
    "# Detect people\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def detect_people(frame, net, ln, personIdx=0):\n",
    "  # grab the dimensions of the frame and  initialize the list of\n",
    "  # results\n",
    "  (H, W) = frame.shape[:2]\n",
    "  results = []\n",
    "  # construct a blob from the input frame and then perform a forward\n",
    "  # pass of the YOLO object detector, giving us our bounding boxes\n",
    "  # and associated probabilities\n",
    "  blob = cv2.dnn.blobFromImage(frame, 1 / 255.0, (416, 416),\n",
    "                                swapRB=True, crop=False)\n",
    "  net.setInput(blob)\n",
    "  layerOutputs = net.forward(ln)\n",
    "\n",
    "  # initialize our lists of detected bounding boxes, centroids, and\n",
    "  # confidences, respectively\n",
    "  boxes = []\n",
    "  centroids = []\n",
    "  confidences = []\n",
    "\n",
    "  # loop over each of the layer outputs\n",
    "  for output in layerOutputs:\n",
    "\t\t# loop over each of the detections\n",
    "    for detection in output:\n",
    "\t\t\t# extract the class ID and confidence (i.e., probability)\n",
    "\t\t\t# of the current object detection\n",
    "      scores = detection[5:]\n",
    "      classID = np.argmax(scores)\n",
    "      confidence = scores[classID]\n",
    "\n",
    "\t\t\t# filter detections by (1) ensuring that the object\n",
    "\t\t\t# detected was a person and (2) that the minimum\n",
    "\t\t\t# confidence is met\n",
    "      if (classID == personIdx) and (confidence > MIN_CONF):\n",
    "\t\t\t\t# scale the bounding box coordinates back relative to\n",
    "\t\t\t\t# the size of the image, keeping in mind that YOLO\n",
    "\t\t\t\t# actually returns the center (x, y)-coordinates of\n",
    "\t\t\t\t# the bounding box followed by the boxes' width and\n",
    "\t\t\t\t# height\n",
    "        box = detection[0:4] * np.array([W, H, W, H])\n",
    "        (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "\n",
    "        # use the center (x, y)-coordinates to derive the top-left\n",
    "        # corner of the bounding box\n",
    "        x = int(centerX - (width / 2))\n",
    "        y = int(centerY - (height / 2))\n",
    "\n",
    "        # update our list of bounding box coordinates,\n",
    "        # centroids, and confidences\n",
    "        boxes.append([x, y, int(width), int(height)])\n",
    "        centroids.append((centerX, centerY))\n",
    "        confidences.append(float(confidence))\n",
    "    \n",
    "  # apply non-maxima suppression to suppress weak, overlapping\n",
    "  # bounding boxes\n",
    "  idxs = cv2.dnn.NMSBoxes(boxes, confidences, MIN_CONF, NMS_THRESH)\n",
    "\n",
    "\t# ensure at least one detection exists\n",
    "  if len(idxs) > 0:\n",
    "    # loop over the indexes we are keeping\n",
    "    for i in idxs.flatten():\n",
    "\t\t\t# extract the bounding box coordinates\n",
    "      (x, y) = (boxes[i][0], boxes[i][1])\n",
    "      (w, h) = (boxes[i][2], boxes[i][3])\n",
    "\n",
    "      # update our results list to consist of the person\n",
    "      # prediction probability, bounding box coordinates,\n",
    "      # and the centroid\n",
    "      r = (confidences[i], (x, y, x + w, y + h), centroids[i])\n",
    "      results.append(r)\n",
    "\n",
    "  # return the list of results\n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2468,
     "status": "ok",
     "timestamp": 1599813725275,
     "user": {
      "displayName": "Parking Incubate",
      "photoUrl": "",
      "userId": "15470270347258067289"
     },
     "user_tz": -120
    },
    "id": "_NLyAVdNrHgk"
   },
   "outputs": [],
   "source": [
    "def classifier_parking(yolo_results, frame):\n",
    "  frame = frame.copy()\n",
    "  results = yolo_results\n",
    "  bays = {'isle1':{1:{'id': 1,  'roi': [  0,  38,  19,  43], 'status': 0}, \n",
    "                  2:{'id': 2,  'roi': [ 20,  40,  55,  50], 'status': 0},\n",
    "                  3:{'id': 3,  'roi': [ 73,  44,  52,  44], 'status': 0},\n",
    "                  19:{'id': 19,  'roi': [125,  41,  49,  48], 'status': 0},\n",
    "                  4:{'id': 4,  'roi': [177,  39,  55,  50], 'status': 0},\n",
    "                  5:{'id': 5,  'roi': [235,  42,  51,  50], 'status': 0},\n",
    "                  6:{'id': 6,  'roi': [290,  33,  52,  55], 'status': 0},\n",
    "                  7:{'id': 7,  'roi': [343,  43,  53,  55], 'status': 0},\n",
    "                  8:{'id': 8,  'roi': [399,  42,  52,  55], 'status': 0},\n",
    "                  9:{'id': 9,  'roi': [455,  40,  53,  51], 'status': 0}, \n",
    "                  10:{'id': 10, 'roi': [510,  41,  50,  48], 'status': 0},\n",
    "                  11:{'id': 11, 'roi': [566,  43,  46,  51], 'status': 0},\n",
    "                  12:{'id': 12, 'roi': [614,  45,  54,  50], 'status': 0},\n",
    "                  13:{'id': 13, 'roi': [670,  41,  56,  51], 'status': 0},\n",
    "                  14:{'id': 14, 'roi': [722,  42,  58,  55], 'status': 0},\n",
    "                  15:{'id': 15, 'roi': [773,  33,  58,  57], 'status': 0},\n",
    "                  16:{'id': 16, 'roi': [835,  38,  50,  53], 'status': 0},\n",
    "                  17:{'id': 17, 'roi': [885,  39,  62,  56], 'status': 0},\n",
    "                  18:{'id': 18, 'roi': [939,  42,  57,  54], 'status': 0},},\n",
    "          \n",
    "          'isle2':{1:{'id': 1,  'roi': [  0, 105,  28,  71], 'status': 0}, \n",
    "                  2:{'id': 2,  'roi': [ 18, 100,  76,  72], 'status': 0},\n",
    "                  3:{'id': 3,  'roi': [ 94,  95,  65,  82], 'status': 0},\n",
    "                  4:{'id': 4,  'roi': [163, 109,  60,  67], 'status': 0},\n",
    "                  5:{'id': 5,  'roi': [234, 104,  63,  75], 'status': 0},\n",
    "                  6:{'id': 6,  'roi': [307, 106,  63,  67], 'status': 0},\n",
    "                  7:{'id': 7,  'roi': [374 ,113,  67,  66], 'status': 0},\n",
    "                  8:{'id': 8,  'roi': [449, 115,  55,  58], 'status': 0},\n",
    "                  9:{'id': 9,  'roi': [512, 123,  63,  56], 'status': 0}, \n",
    "                  10:{'id': 10, 'roi': [579, 121,  71,  54], 'status': 0},\n",
    "                  11:{'id': 11, 'roi': [656, 118,  72,  61], 'status': 0},\n",
    "                  12:{'id': 12, 'roi': [730, 112,  68,  64], 'status': 0},\n",
    "                  13:{'id': 13, 'roi': [792, 115,  71,  63], 'status': 0},\n",
    "                  14:{'id': 14, 'roi': [868, 119,  76,  65], 'status': 0}},\n",
    "          \n",
    "          'isle3':{1:{'id': 1,  'roi': [  0, 179,  75,  68], 'status': 0}, \n",
    "                  2:{'id': 2,  'roi': [ 74, 175,  91,  86], 'status': 0},\n",
    "                  3:{'id': 3,  'roi': [165, 178,  87,  97], 'status': 0},\n",
    "                  4:{'id': 4,  'roi': [255, 181,  86,  89], 'status': 0},\n",
    "                  5:{'id': 5,  'roi': [344, 181,  82,  89], 'status': 0},\n",
    "                  6:{'id': 6,  'roi': [434, 171,  78, 108], 'status': 0},\n",
    "                  7:{'id': 7,  'roi': [515, 187,  86,  85], 'status': 0},\n",
    "                  8:{'id': 8,  'roi': [596, 191,  82,  71], 'status': 0},\n",
    "                  9:{'id': 9,  'roi': [667, 186, 107,  87], 'status': 0}, \n",
    "                  10:{'id': 10, 'roi': [752, 188,  95,  78], 'status': 0},\n",
    "                  11:{'id': 11, 'roi': [830, 170, 100,  88], 'status': 0},\n",
    "                  12:{'id': 12, 'roi': [925, 186,  75,  85], 'status': 0}},\n",
    "\n",
    "          'isle4':{1:{'id': 1, 'roi': [  0, 359, 112, 180], 'status': 0}, \n",
    "                  2:{'id': 2, 'roi': [105, 365, 135, 174], 'status': 0},\n",
    "                  3:{'id': 3, 'roi': [258, 373, 122, 162], 'status': 0},\n",
    "                  4:{'id': 4, 'roi': [396, 383, 121, 157], 'status': 0},\n",
    "                  5:{'id': 5, 'roi': [518, 367, 141, 170], 'status': 0},\n",
    "                  6:{'id': 6, 'roi': [647, 356, 145, 183], 'status': 0},\n",
    "                  7:{'id': 7, 'roi': [778, 368, 158, 174], 'status': 0},\n",
    "                  8:{'id': 8, 'roi': [906, 338,  94, 196], 'status': 0}},\n",
    "\n",
    "          'isle5':{1:{'id': 1, 'roi': [  4, 653, 358,  97], 'status': 0}, \n",
    "                  2:{'id': 2, 'roi': [362, 653, 404,  97], 'status': 0},\n",
    "                  3:{'id': 3, 'roi': [766, 647, 234, 103], 'status': 0}}\n",
    "          } #status =1 => occupied\n",
    "\n",
    "  for i in range(1, 6):\n",
    "    aisle = 'isle'+str(i)\n",
    "    for bay in bays[aisle]:\n",
    "        x,y,w,h = bays[aisle][bay]['roi']\n",
    "        # print(f'\\n\\n({x}, {y}) -> ({x+w}, {y+h})')\n",
    "        # print('\\n\\n')\n",
    "        for (i, (prob, bbox, centroid)) in enumerate(results):\n",
    "          # print(f'centroid: {centroid}')\n",
    "          # print(f'x in: {(x < centroid[0] < x+w)}; y in: {(y < centroid[1] < y+h)}')\n",
    "          # print(f\"({x} < {centroid[0]} < {x+w}) and ({y} < {centroid[1]} < {y+h})\")\n",
    "          if (x < centroid[0] < x+w) and (y < centroid[1] < y+h):\n",
    "            bays[aisle][bay]['status'] = 1\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 255, 255), 5)\n",
    "            # print('sucess')\n",
    "            break\n",
    "          else:\n",
    "            bays[aisle][bay]['status'] = 0\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 3)\n",
    "\n",
    "  return bays, frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3654,
     "status": "ok",
     "timestamp": 1599813731054,
     "user": {
      "displayName": "Parking Incubate",
      "photoUrl": "",
      "userId": "15470270347258067289"
     },
     "user_tz": -120
    },
    "id": "UJAvZnMUVEB3"
   },
   "outputs": [],
   "source": [
    "# read images from folder called Parking 8\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "folders = [\"2015-11-16/camera8/\", \n",
    "           \"2015-11-20/camera8/\", \n",
    "           '2015-11-25/camera8/', \n",
    "           '2015-11-29/camera8/',\n",
    "           \"2015-12-03/camera8/\", \n",
    "           \"2015-12-18/camera8/\",\n",
    "           \"2015-12-19/camera8/\"]\n",
    "\n",
    "fs = []\n",
    "for folder in folders:\n",
    "  mypath = f\"/content/drive/My Drive/Parking 8/{folders[1]}\"\n",
    "  for f in listdir(mypath):\n",
    "    if isfile(join(mypath, f)):\n",
    "      fs.append(join(mypath, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "15ej4hSj14wEHVOlVTEFhyztzROMf1uIc"
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 379184,
     "status": "ok",
     "timestamp": 1599814112608,
     "user": {
      "displayName": "Parking Incubate",
      "photoUrl": "",
      "userId": "15470270347258067289"
     },
     "user_tz": -120
    },
    "id": "Nc_nzEiA0H1D",
    "outputId": "3187c7d6-9b8a-407a-9d36-c17cab2ee7cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output hidden; open in https://colab.research.google.com to view."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# apply detection\n",
    "from scipy.spatial import distance as dist\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# load the COCO class labels our YOLO model was trained on\n",
    "labelsPath = os.path.sep.join([MODEL_PATH, \"coco.names\"])\n",
    "LABELS = open(labelsPath).read().strip().split(\"\\n\")\n",
    "\n",
    "# derive the paths to the YOLO weights and model configuration\n",
    "weightsPath = os.path.sep.join([MODEL_PATH, \"yolov3.weights\"])\n",
    "configPath = os.path.sep.join([MODEL_PATH, \"yolov3.cfg\"])\n",
    "\n",
    "# load our YOLO object detector trained on COCO dataset (80 classes)\n",
    "print(\"[INFO] loading YOLO from disk...\")\n",
    "net = cv2.dnn.readNetFromDarknet(configPath, weightsPath)\n",
    " \n",
    "# determine only the *output* layer names that we need from YOLO\n",
    "ln = net.getLayerNames()\n",
    "ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "\n",
    "# loop over the frames from the video stream\n",
    "# while True:\n",
    "# read the next frame from the file\n",
    "for f in fs:\n",
    "  print(f\"{f[-20:]}\")\n",
    "  frame = cv2.imread(f)\n",
    "  frame2 = frame.copy()\n",
    "  # plt.imshow(frame)\n",
    "  # plt.show()\n",
    "\n",
    "  # detect cars in it\n",
    "  results = detect_people(frame, net, ln,\n",
    "                          personIdx=LABELS.index(\"car\"))\n",
    "\n",
    "  #anotate\n",
    "  # loop over the results\n",
    "  for (i, (prob, bbox, centroid)) in enumerate(results):\n",
    "    # extract the bounding box and centroid coordinates, then\n",
    "    # initialize the color of the annotation\n",
    "    (startX, startY, endX, endY) = bbox\n",
    "    (cX, cY) = centroid\n",
    "    color = (0, 255, 0)\n",
    "\n",
    "    # draw (1) a bounding box and (2) the centroid coordinates,\n",
    "    # cv2.rectangle(frame, (startX, startY), (endX, endY), color, 2)\n",
    "    cv2.circle(frame, (cX, cY), 5, color, -1)\n",
    "  \n",
    "  frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "  frame2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2RGB)\n",
    "  bays, frame2 = classifier_parking(results, frame2)\n",
    "  plt.imshow(frame)\n",
    "  plt.show()\n",
    "  plt.imshow(frame2)\n",
    "  plt.show()\n",
    "  print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hbBUBEj0ZTMq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOfl/ldytQ9woGXngPqf0lH",
   "collapsed_sections": [],
   "mount_file_id": "1pNIlCNopX0ps1U9Y9R0Ap3HPtm2DKxGM",
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
